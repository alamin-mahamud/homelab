---
# Complete K8s Cluster Deployment Playbook
# Deploys a production-ready Kubernetes cluster with HA control plane

- name: Pre-flight checks and preparation
  hosts: all
  become: yes
  gather_facts: yes
  tasks:
    - name: Verify connectivity to all nodes
      ping:
      
    - name: Set hostname
      hostname:
        name: "{{ inventory_hostname }}"
        
    - name: Update /etc/hosts
      lineinfile:
        path: /etc/hosts
        line: "{{ hostvars[item]['ansible_host'] }} {{ item }}"
        state: present
      with_items: "{{ groups['all'] }}"

- name: Install container runtime and Kubernetes components
  hosts: k8s_cluster
  become: yes
  roles:
    - role: k8s-prerequisites
    - role: containerd
    - role: kubernetes-base
  
- name: Initialize first master node
  hosts: k8s_masters[0]
  become: yes
  tasks:
    - name: Check if cluster is already initialized
      stat:
        path: /etc/kubernetes/admin.conf
      register: kubeconfig_stat
      
    - name: Initialize Kubernetes cluster
      command: |
        kubeadm init \
          --control-plane-endpoint "{{ k8s_api_vip }}:6443" \
          --upload-certs \
          --pod-network-cidr="{{ k8s_pod_subnet }}" \
          --service-cidr="{{ k8s_service_subnet }}" \
          --apiserver-advertise-address="{{ ansible_host }}"
      when: not kubeconfig_stat.stat.exists
      register: kubeadm_init
      
    - name: Create .kube directory
      file:
        path: "/home/ubuntu/.kube"
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'
        
    - name: Copy admin.conf to user's kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/ubuntu/.kube/config
        remote_src: yes
        owner: ubuntu
        group: ubuntu
        mode: '0600'
        
    - name: Get join command for control plane
      command: kubeadm token create --print-join-command
      register: join_command
      
    - name: Get certificate key for control plane join
      command: kubeadm init phase upload-certs --upload-certs
      register: cert_key
      when: groups['k8s_masters'] | length > 1
      
    - name: Set join facts
      set_fact:
        kubeadm_join_command: "{{ join_command.stdout }}"
        kubeadm_cert_key: "{{ cert_key.stdout_lines[-1] if cert_key is defined else '' }}"

- name: Join additional master nodes
  hosts: k8s_masters[1:]
  become: yes
  tasks:
    - name: Check if node is already joined
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf
      
    - name: Join master to cluster
      command: >
        {{ hostvars[groups['k8s_masters'][0]]['kubeadm_join_command'] }}
        --control-plane
        --certificate-key {{ hostvars[groups['k8s_masters'][0]]['kubeadm_cert_key'] }}
        --apiserver-advertise-address {{ ansible_host }}
      when: not kubelet_conf.stat.exists

- name: Join worker nodes
  hosts: k8s_workers
  become: yes
  tasks:
    - name: Check if node is already joined
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf
      
    - name: Join worker to cluster
      command: "{{ hostvars[groups['k8s_masters'][0]]['kubeadm_join_command'] }}"
      when: not kubelet_conf.stat.exists
      
    - name: Label storage workers
      delegate_to: "{{ groups['k8s_masters'][0] }}"
      run_once: yes
      k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ inventory_hostname }}"
            labels:
              node-role.kubernetes.io/worker: ""
              storage: "{{ 'longhorn' if worker_type == 'storage' else 'none' }}"
      when: worker_type is defined

- name: Deploy CNI and core components
  hosts: k8s_masters[0]
  become: yes
  become_user: ubuntu
  tasks:
    - name: Deploy Flannel CNI
      k8s:
        state: present
        src: https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
        
    - name: Deploy metrics-server
      k8s:
        state: present
        src: https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
        
    - name: Wait for all nodes to be ready
      k8s_info:
        api_version: v1
        kind: Node
      register: nodes
      until: nodes.resources | selectattr('status.conditions') | map(attribute='status.conditions') | flatten | selectattr('type', 'equalto', 'Ready') | selectattr('status', 'equalto', 'True') | list | length == groups['k8s_cluster'] | length
      retries: 30
      delay: 10
      
    - name: Create priority classes
      k8s:
        state: present
        definition:
          apiVersion: scheduling.k8s.io/v1
          kind: PriorityClass
          metadata:
            name: "{{ item.name }}"
          value: "{{ item.value }}"
          globalDefault: "{{ item.default | default(false) }}"
          description: "{{ item.description }}"
      with_items:
        - { name: system-critical, value: 2000000000, description: "System critical components" }
        - { name: high-priority, value: 1000000000, description: "High priority workloads" }
        - { name: normal-priority, value: 0, default: true, description: "Normal priority workloads" }
        - { name: low-priority, value: -1000000000, description: "Low priority workloads" }

- name: Configure HAProxy load balancers
  hosts: haproxy
  become: yes
  tasks:
    - name: Install HAProxy
      apt:
        name: haproxy
        state: present
        update_cache: yes
        
    - name: Configure HAProxy for K8s API
      template:
        src: haproxy-k8s.cfg.j2
        dest: /etc/haproxy/haproxy.cfg
        backup: yes
      notify: restart haproxy
      
    - name: Enable and start HAProxy
      systemd:
        name: haproxy
        enabled: yes
        state: started
        
  handlers:
    - name: restart haproxy
      systemd:
        name: haproxy
        state: restarted
        
- name: Cluster validation
  hosts: k8s_masters[0]
  become: yes
  become_user: ubuntu
  tasks:
    - name: Get cluster info
      command: kubectl cluster-info
      register: cluster_info
      
    - name: Get nodes status
      command: kubectl get nodes -o wide
      register: nodes_status
      
    - name: Display cluster information
      debug:
        msg:
          - "Cluster Info:"
          - "{{ cluster_info.stdout_lines }}"
          - ""
          - "Nodes Status:"
          - "{{ nodes_status.stdout_lines }}"